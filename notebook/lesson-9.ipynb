{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, openai, pprint, dotenv\n",
    "from typing import Dict\n",
    "\n",
    "from langchain.chains import SequentialChain, LLMChain\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../python')\n",
    "from utils import is_pdf_by_signature, encode_image, pdf_to_image, extract_json_from_string\n",
    "from tools import search_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 환경 변수에서 API 키 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv('../.env')\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE-SEARCH-API-KEY\")\n",
    "SEARCH_ENGINE_ID = os.getenv(\"SEARCH-ENGINE-ID\")\n",
    "openai.api_key = os.getenv(\"OPEN-AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCRChain(Chain):\n",
    "    \"\"\"\n",
    "    OpenAI를 이용해서 OCR을 진행하는 사용자 정의 체인.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @property\n",
    "    def input_keys(self):\n",
    "        return [\"image_path\"]\n",
    "\n",
    "    @property\n",
    "    def output_keys(self):\n",
    "        return [\"ocr_response\"]  # 출력값으로 Assistant의 응답을 반환\n",
    "\n",
    "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
    "        image_path = inputs[\"image_path\"]\n",
    "        # print(f\"Image path: {image_path}\")\n",
    "        try:\n",
    "            # 이미지 파일 열기\n",
    "            if is_pdf_by_signature(image_path):\n",
    "                base64_image = pdf_to_image(image_path)\n",
    "            else:\n",
    "                base64_image = encode_image(image_path)\n",
    "            response = openai.chat.completions.create(\n",
    "                model=\"gpt-4o\",  # GPT-4 Vision 모델 사용\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"You are an assistant that extracts information from receipt images.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": '''다음 텍스트는 영수증의 정보입니다. 이 텍스트에서 가게 이름, 날짜, 항목, 총액을 분석하고, 아래의 JSON형식으로 결과를 반환해 주세요.\n",
    "                                JSON 형식:\n",
    "                                {\n",
    "                                    \"상호명\": \"가게 이름\",\n",
    "                                    \"날짜\": \"YYYY-MM-DD\",\n",
    "                                    \"항목\": [\n",
    "                                        {\"이름\": \"상품1\", \"가격\": 상품1 가격},\n",
    "                                        {\"이름\": \"상품2\", \"가격\": 상품2 가격}\n",
    "                                    ],\n",
    "                                    \"총액\": 총액\n",
    "                                }\n",
    "                                반환할 JSON 형식은 반드시 위의 구조와 일치해야 하며, 불필요한 설명은 포함하지 마세요.\n",
    "                                영수증 텍스트:\n",
    "                                \"\"\"\n",
    "                                [여기에 영수증의 텍스트 또는 OCR로 추출한 내용이 들어갑니다]\n",
    "                                \"\"\"\n",
    "                                결과:''' \n",
    "                            },{\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "                            }\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "            )\n",
    "            \n",
    "            # 응답 파싱\n",
    "            raw_response = extract_json_from_string(response.choices[0].message.content)\n",
    "            return {\"ocr_response\": raw_response}\n",
    "        except Exception as e:\n",
    "            \n",
    "            return {\"ocr_response\": f\"Error during OpenAI API call: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"../image/example.jpg\"  # 실제 이미지 파일 경로를 여기에 설정\n",
    "# OCRChain 초기화\n",
    "ocr_chain = OCRChain()\n",
    "ocr_response = ocr_chain.invoke({\"image_path\": image_path})\n",
    "pprint.pprint(ocr_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SearchChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchChain(Chain):\n",
    "    def __init__(self, tool):\n",
    "        super().__init__()\n",
    "        self._tool = tool\n",
    "\n",
    "    @property\n",
    "    def input_keys(self):\n",
    "        return [\"ocr_response\"]\n",
    "\n",
    "    @property\n",
    "    def output_keys(self):\n",
    "        return [\"search_results\", \"business_name\"]\n",
    "\n",
    "    def _call(self, inputs, **kwargs):\n",
    "        business_name = inputs['ocr_response'][\"상호명\"]\n",
    "        item = ','.join([x[\"이름\"] for x in inputs['ocr_response']['항목']])\n",
    "        if len(item) > 0:\n",
    "            query = ','.join([business_name, item])\n",
    "        else:\n",
    "            query = business_name\n",
    "        search_results = self._tool.func(query)\n",
    "        return {\"search_results\": search_results, \"business_name\": business_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SearchChain 초기화\n",
    "search_chain = SearchChain(search_tool)\n",
    "search_response = search_chain.invoke(ocr_response)\n",
    "pprint.pprint(search_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 정의\n",
    "analysis_prompt = PromptTemplate(\n",
    "    input_variables=[\"business_name\", \"search_results\"],\n",
    "    template=\"\"\"\n",
    "    다음은 상호명 '{business_name}'에 대한 검색 결과입니다:\n",
    "    {search_results}\n",
    "    검색 결과를 기반으로 해당 상호의 업종을 추론하세요. 가능한 경우 단답형으로 업종만 답변하세요.\n",
    "    예: \"식당\", \"카페\", \"의류\", \"교통\" 등.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과를 분석하는 LLMChain\n",
    "analysis_chain = LLMChain(\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4\", \n",
    "        temperature=0,\n",
    "        openai_api_key = openai.api_key\n",
    "    ),\n",
    "    prompt=analysis_prompt,\n",
    "    output_key=\"business_category\",  # 출력 키를 명시적으로 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SequentialChain 구성\n",
    "sequential_chain = SequentialChain(\n",
    "    chains=[ocr_chain, search_chain, analysis_chain],\n",
    "    input_variables=[\"image_path\"],\n",
    "    output_variables=[\"business_category\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행\n",
    "image_path = \"../image/example.jpg\"  # 실제 이미지 파일 경로를 여기에 설정\n",
    "result = sequential_chain.invoke({\"image_path\": image_path})\n",
    "print(\"\\n최종 결과:\")\n",
    "print(result[\"business_category\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "receipt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
